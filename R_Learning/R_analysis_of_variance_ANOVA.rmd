---
title: "R Notebook about R_Analysis_of_Variance"
output: 
  html_notebook: 
    toc: yes
    toc_depth: 4
---

# R Notebook about R_Analysis_of_Variance_ANOVA

## 一、单因子方差分析（one-way ANOVA）

### 1)建模：

我们采用multcomp包中的cholesterol数据集作为例子，其中response为响应变量，trt为预测变量，这个处理中有五种水平。从下面的箱形图中可观察到处理的不同水平对于响应变量的影响。再用aov函数建立单因子方差模型，从结果的P值可看到各组均值有显著不同。

```{r model}
install.packages("multcomp")
data(cholesterol)

aggregate(response, by=list(trt), FUN=mean)
bwplot(response~trt)
model=aov(response~trt)
summary(model)
```

### 2)多重比较：

方差分析只告诉我们这五组之间是不同的，但没有告诉我们哪两组之间有明显差别，此时需要使用TukeyHSD函数进行均值的多重比较分析，从结果中观察到有三个两两比较是不显著的。

```{r}
(result=TukeyHSD(model))
plot(result)
```

### 3)假设检验：

方差分析需要一定的假设，即数据集应该符合正态和同方差，我们分别用下面的函数来进行检验，从P值观察到这两个假设是符合的。

对于不符合假设的情况，我们就要用到非参数方法，例如Kruskal-Wallis秩和检验

```{r shapiro.test and bartlett.test}
shapiro.test(response)
bartlett.test(response~trt)
```

## 二、双因子方差分析（Two-way Factorial ANOVA）

我们用ToothGrowth数据集来举例双因子方差分析。其中supp和dose是预测变量，len是响应变量。我们仍然使用aov进行建模，然后使用HH包的绘图函数来展现双因子交互效果图

```{r}
fit <- aov(len ~ supp*dose)
library(HH)
interaction2wt(len~supp*dose)
```

要注意在下面的情况下因子的先后顺序是有讲究的：

第一种情况是多因子非平衡情况下，此时重要的因子应该放在前面
，
第二是在在有协变量情况下，此时协变量放在前面，然后是主因子和交互因子

## 三、重复测量方差分析

在重复测量的方差分析中，实验对象被测量多次，所以会存在组内因子，组内因子要以下面的形式特别标明出来，其中B是组间因子，W是组内因子，subject是实验对象的ID，

```{r}
model=aov(Y ~ B * W + Error(Subject/W))
```

上述方法的前提是对应组内因子不同水平的数据是等方差的，当传统方法的假设得不到满足时，则应用lme4包中lmer函数，利用混合效应模型来解决问题。

## 四、回归方程的显著性检验

> http://blog.fens.me/r-linear-regression/

从回归参数的公式二可知，在计算过程中并不一定要知道Y和X是否有线性相关的关系。如果不存相关关系，那么回归方程就没有任何意义了，如果Y和X是有相关关系的，即Y会随着X的变化而线性变化，这个时候一元线性回归方程才有意义。所以，我们需要用假设检验的方法，来验证相关性的有效性。

通常会采用三种显著性检验的方法。

T检验法：T检验是检验模型某个自变量Xi对于Y的显著性，通常用`P-value`判断显著性，小于0.01更小时说明这个自变量Xi与Y相关关系显著。

F检验法：F检验用于对所有的自变量X在整体上看对于Y的线性显著性，也是用`P-value`判断显著性，小于0.01更小时说明整体上自变量与Y相关关系显著。

`R^2` (R平方)相关系统检验法：用来判断回归方程的拟合程度，`R^2` 的取值在0，1之间，越接近1说明拟合程度越好。

在R语言中，上面列出的三种检验的方法都已被实现，我们只需要把结果解读。上文中，我们已经通过`lm()`函数构建一元线性回归模型，然后可以`summary()`函数来提取模型的计算结果。

```{r module}
summary(lm.ab)      # 计算结果

# Call:
# lm(formula = y ~ 1 + x)
# 
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -11.9385  -2.2317  -0.1797   3.3546  10.2766 
# 
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept) -3.495e+02  7.173e+01  -4.872 2.09e-06 ***
# x            1.029e+00  5.111e-03 201.390  < 2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 4.232 on 223 degrees of freedom
# Multiple R-squared:  0.9945,	Adjusted R-squared:  0.9945 
# F-statistic: 4.056e+04 on 1 and 223 DF,  p-value: < 2.2e-16

```
### 模型解读：

`Call`，列出了回归模型的公式。

`Residuals`，列出了残差的最小值点，1/4分位点，中位数点，3/4分位点，最大值点。

`Coefficients`，表示参数估计的计算结果。

`Estimate`，为参数估计列。Intercept行表示常数参数a的估计值 ，x行表示自变量x的参数b的估计值
。

`Std. Error`，为参数的标准差，`sd(a)`, `sd(b)`

`t value`，为t值，为T检验的值

`Pr(>|t|)` ，表示P-value值，用于T检验判定，匹配显著性标记
显著性标记，***为非常显著，**为高度显著, **为显著，·为不太显著，没有记号为不显著。

`Residual standard error`，表示残差的标准差，自由度为n-2。

`Multiple R-squared`，为相关系数R^2的检验，越接近1则越显著。

`Adjusted R-squared`，为相关系数的修正系数，解决多元回归自变量越多，判定系数R^2越大的问题。

`F-statistic`，表示F统计量，自由度为(1,n-2)，p-value:用于F检验判定，匹配显著性标记。

通过查看模型的结果数据，我们可以发现通过T检验的截距和自变量x都是非常显著，通过F检验判断出整个模型的自变量是非常显著，同时R^2的相关系数检验可以判断自变量和因变量是高度相关的。

最后，我们通过的回归参数的检验与回归方程的检验，得到最后一元线性回归方程为：
`Y = -349.493 + 1.029315 * X` 

