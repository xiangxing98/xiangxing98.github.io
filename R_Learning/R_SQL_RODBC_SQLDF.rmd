---
title: "R Notebook R_SQL_RODBC_SQLDF"
author: "Stone_Hou"
date: "`r Sys.Date()`"
output:
  html_notebook:
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 4
---

# R Notebook R_SQL_RODBC_SQLDF

## 1. RODBC

CRAN 里面的包 RODBC 提供了 ODBC的访问接口：

* odbcConnect 或 odbcDriverConnect（在Windows图形化界面下，可以通过对话框选择数据库） 可以打开一个连接，返回一个用于随后数据库访问的控制（handle）。 打印一个连接会给出ODBC连接的一些细节，而调用 odbcGetInfo 会给出客户端和服务器的一些细节信息。

* 在一个连接中的表的细节信息可以通过函数 sqlTables 获得。

* 函数 sqlSave 会把 R 数据框复制到一个数据库的表中， 而函数 sqlFetch 会把一个数据库中的表拷贝到 一个 R 的数据框中。

* 通过sqlQuery进行查询，返回的结果是 R 的数据框。（sqlCopy把一个 查询传给数据库，返回结果在数据库中以表的方式保存。） 一种比较好的控制方式是首先调用 odbcQuery， 然后 用 sqlGetResults 取得结果。后者可用于一个循环中 每次获得有限行，就如函数 sqlFetchMore 的功能。

* 连接可以通过调用函数 close 或 odbcClose 来关闭。 没有 R 对象对应或不在 R 会话后面的连接也可以调用这两个函数来关闭， 但会有警告信息。

```{r RODBC}
# http://blog.csdn.net/sinat_26917383/article/details/51100736
#安装RODBC包  
install.packages("RODBC")   
library(RODBC)  
mycon<-odbcConnect("mydsn",uid="root",pwd="082408SQ")  
#通过一个数据源名称（mydsn）和用户名（user）以及密码（rply，如果没有设置，可以直接忽略）打开了一个ODBC数据库连接  
  
data(USArrests)  
#将R自带的“USArrests”表写进数据库里  
sqlSave(mycon,USArrests,rownames="state",addPK=TRUE)  
#将数据流保存，这时打开SQL Server就可以看到新建的USArrests表了  
rm(USArrests)  
#清除USArrests变量  
  
sqlFetch(mycon, "USArrests" ,rownames="state")  
#输出USArrests表中的内容  
sqlQuery(mycon,"select * from USArrests")  
#对USArrests表执行了SQL语句select，并将结果输出  
  
sqlDrop(channel,"USArrests")  
#删除USArrests表  
close(mycon)  
#关闭连接  
```

### sqlSave函数

```{r sqlSave}
sqlSave(channel, dat, tablename = NULL, append = FALSE,  
        rownames = TRUE, colnames = FALSE, verbose = FALSE,  
        safer = TRUE, addPK = FALSE, typeInfo, varTypes,  
        fast = TRUE, test = FALSE, nastring = NULL)  
```

其中这个函数的使用还是很讲究的，参数的认识很重要。

append代表是否追加，默认不追加，如果一张已经有数据的表，就可以用append追加新的数据，需要同样的column，一般开个这个就行。

rownames，可以是逻辑值，也可以是字符型。

colnames，列名；

verbose，默认为FALSE，是否发送语句到R界面，如果TRUE，那么每条上传数据就会出现在命令栏目致之中。

addPK,是否将rownames指定为主键。

### sqlUpdate函数
```{r sqlUpdate}
sqlUpdate(channel, dat, tablename = NULL, index = NULL,  
          verbose = FALSE, test = FALSE, nastring = NULL,  
          fast = TRUE)  
```


## 2. sqldf包

### 1、SQL基本特点

SQL语句语句特点：先全局选择，再局部选择
Select * from sale where year=2010 and ...

where后面可以接很多，有比较运算符，算数运算符，逻辑运算符。
比较运算符号：=(等于，不是双引号)；!=（不等于）；>，<，>=，<=
算数运算符：*，/，+，-
逻辑运算符：&&(and,与)， ||（or，或） ，!（,not非）

### 2、数据筛选与排序

数据筛选可以有subset函数，排序有order/sort函数

```{r sqldf}
#选择表中指定列*/  
sqldf("select year,market,sale,profit from sale")  
  
#选择满足条件的行*/  
sqldf("select * from sale where year=2012 and market='东'")  
   #语句特点，先抽取全局数据，然后再执行局部选择  
   #字符单引号，切记  
  
#对行进行排序*/  
sqldf("select year,market,sale,profit  
      from sale  
      order by year")  
```
数据筛选：sqldf可以执行选择表中指定指标、满足条件的行（注意：抽取满足条件的行的字符时，字符型需要用单引号），语法结构是：
select  指标名称 from 数据集 where 某指标=条件  

排序order：按照某变量排序，语法结构：
select 指标名称（或全部）from 数据集 order by 指标名称

### 3、数据合并——纵向连接

数据合并的方法很多，基本函数包中有merge、cbind/rbind，以及一些专业的包plyr、dplyr、data.table等
rbind/cbind对数据合并的要求比较严格：合并的变量名必须一致；数据等长；指标顺序必须一致。
sqldf就不会这么苛刻，并参照了一些集合查询的方法

####（1）并——union
```{r}
UNION3<-sqldf("select * from one union select * from two")  
   #合并后去重,rbind是合并后不去重  
UNION_all<-sqldf("select * from one union all select * from two")  
   #all可以支持，合并后不去重  
```
rbind/cbind是将数据一股脑子全部帖在一起，只合并不去重；sqldf则可以自行选择，语法结构：
select * from 数据集1 union (all) select * from 数据集2
其中的all代表不去重，一起加进来。

####（2）差(except)、交（Intersect）

差集就是找两个数据集的不同的数据，而且是数据集1中，去掉重复的数值；并集则是两个数据集的重合（去重可以用）之处。

```{r}
#EXCEPT_差集  
   #不存在all  
EXCEPT<-sqldf("select * from one EXCEPT select * from two")  
  
#INTERSECT——交集  
INTERSECT<-sqldf("select * from one INTERSECT select * from two")  
```

### 4、数据合并——横向连接

横向连接有三种类型：交叉连接（笛卡尔乘积，大乱炖所有数据重新排列组合合并起来，一般在实验设计涉及全排列的时候可以很好地使用）、内连接（筛选匹配到的数据）、外连接。

#### （1）内连接——匹配到完全一致的
```{r}
inner1<- merge(table1, table2, by = "id", all = F);inner1  #筛选相同id，F为只连接匹配到的，T为没有匹配到的赋值NA  
#   id a b  
# 1  3 c e  
inner2<-inner_join(table1, table2, by = "id");inner2   #与merge完全一致  
#   id a b  
# 1  3 c e  
inner3<-sqldf("select * from table1 as a inner join table2 as b on a.id=b.id");inner3 #内连接  
#   id a id b  
# 1  3 c  3 e  
inner4<-sqldf("select * from table1 as a,table2 as b where a.id=b.id");inner4  #笛卡尔积  
#   id a id b  
# 1  3 c  3 e  
```
匹配到完全一致、相同的，基础包merge=dplyr的inner_join=sqldf包中的inner join。当然输出结果中，sqldf中会蹦出来两个id，可以进行删除。
其中sql包中的Inner join语法结构为：
select * from 数据集1 as a      inner join   数据集2  as b on a.指标名称=b.指标名称 

####（2）左连接——最有效，以数据集1为准，匹配到的+为匹配到的
```{r}
left1<- merge(table1, table2, by = "id", all.x = TRUE);left1  #按照id连接所有信息包括进去  
#   id a    b  
# 1  1 a <NA>  
# 2  2 b <NA>  
# 3  3 c    e 

left2<-left_join(table1, table2, by = "id");left2  
#   id a    b  
# 1  1 a <NA>  
# 2  2 b <NA>  
# 3  3 c    e  

left3<-sqldf("select * from table1 as a left join table2 as b on a.id=b.id");left3  
#   id a id    b  
# 1  1 a NA <NA>  
# 2  2 b NA <NA>  
# 3  3 c  3    e 
```
基础包中的merge，当all=F就是内连接，all=T就是全连接，all.x=T就是左联结，all.y=T就是右连接（merge函数首选all=T,全连接）；dplyr中的left_join也可以实现merge,all=T效果
sqldf中的语法结构：
select * from 数据集1 as a left join 数据集2as b on a.指标名称=b.指标名称

### 5、数据去重

解读：distinct跟unique去重功能差不多，语法特点：
select DISTINCT 指标名称 from 数据集

```{r}
#删除重复的行*/  
sqldf("select DISTINCT  year from sale")  
```

### 6. 批量读入文件夹中的文本文件（*.txt），并生成名称、文档数据框

代码思路：先遍历文件夹中所有txt（list.files）、构造文本读入函数（read.txt）、找文本名字（list.files）、然后生成数据框（as.data.frame）

```{r}
##批量读入txt文件，并将文本放入同一个数据框  
reviewpath <- "F:/R语言/R语言与文本挖掘/情感分析/数据/rawdata/review_sentiment/train2"  
completepath <- list.files(reviewpath, pattern = "*.txt$", full.names = TRUE)  
  
######批量读入文本  
read.txt <- function(x) {  
  des <- readLines(x)                   #每行读取  
  return(paste(des, collapse = ""))     #没有return则返回最后一个函数对象  
}  
review <- lapply(completepath, read.txt)  
#如果程序警告，这里可能是部分文件最后一行没有换行导致，不用担心。  
  
######list转数据框  
docname <- list.files(reviewpath, pattern = "*.txt$")  
reviewdf <- as.data.frame(cbind(docname, unlist(review)),   
                          stringsAsFactors = F)   
# 其中，list.files（）中，full.names=T代表读入文件+信息，full.names=F代表读入文件名字。
```




## 3. load package in a safe way

```{r load package in a safe way}
# Load data.table package
if(!suppressWarnings(require('data.table')))
{
    install.packages('data.table')
    require('data.table')
}

```




## 4. Input Data -> manupulation -> Output data

数据处理的流程：数据输入-> 处理 -> 结果输出

```{r duplicated ex1}
# Record Current Date and time
DateTime <- format(Sys.time(), "%Y-%m-%d %H-%M-%S")

# load stop_word file, one line as one element, 
# character vector
stop_word_file_path <- file.choose()
# stop_word_file_path
# [1] "E:\\03-Download\\Github\\xiangxing98.github.io\\R_Learning\\stop_words_duplicated_no_unique.utf8.txt"

stop_word_file_directory <- dirname(stop_word_file_path)
# stop_word_file_directory
# [1] "E:/03-Download/Github/xiangxing98.github.io/R_Learning"

# scan and read stop_words_duplicated_no_unique.utf8.txt
stop_word <- scan(stop_word_file_path, sep="\n", what="", encoding="UTF-8")

# 删掉所有列上都重复的并赋值给新的变量
# (stop_word_unique <- stop_word[!duplicated(stop_word)])
stop_word_unique <- stop_word[!duplicated(stop_word)]

# 保存去除重复后的向量到新的文件
new_file_name <- paste("stop_words_unique-",DateTime,".utf8.txt", sep = "")

# UTF8 Encoding
writeLines(stop_word_unique, "E:/03-Download/Github/stop_word_unique.txt", useBytes=T)

readLines("E:/03-Download/Github/stop_word_unique.txt", encoding="UTF-8")
```

## 用R语言分析聊天记录

> [https://zhuanlan.zhihu.com/p/31201177](https://zhuanlan.zhihu.com/p/31201177)

### 数据处理
```{r}
library(RSQLite)
library(plyr)
# //连接SQLitle数据库

conn <- dbConnect(dbDriver("SQLite"), dbname="MM.sqlite")
# //设置连接函数

doCountQuery <- function(conn,table){
    query <- paste("SELECT COUNT(name) FROM ",table,sep ="")
    t <- dbGetQuery(conn,query)    return(t)
}

table_name <- dbGetQuery(conn, "SELECT name FROM sqlite_master where type='table' and name like 'Chat_%' order by name")
# //取出所有表名，由于不会遍历，只能按照最笨的办法，计算哪个表的数据量最多，即是和男盆友的聊天记录表，如果不是和男盆友的聊天表，此方法是找不出来

counts <- numeric(0)for (i in 1:length(table_name) ){
    count <- doCountQuery(conn,table_name[i])
    counts[i] <-count[[1]]    
}
# //计算表长
table_count <- data.frame(counts)

# //排序，表长最大的表，即是和男朋友的聊天记录表
table_count1 <- table_count[order(table_count$counts,decreasing=TRUE),]

# //提取到聊天内容
message <- dbGetQuery(conn, "SELECT * FROM Chat_XXXXXXXXXX ")
```

### 文本分析

```{r}
library(jiebaRD)
library(jiebaR)

library(data.table)
library(stringr)

cutter=worker()
wechat_content =message
wechat_content <- as.character(wechat_word$V1)
# ///由于数据量过大，不知道为什么只用cuter无法把所有数据都遍历到，无奈只能写简单的函数每一条遍历切割

cut_y <- function (y){
    y=gsub("\\.","",y)
    cutter[as.character(y)]
}
# //遍历切割每一条聊天内容
y.out <- sapply(wechat_content,cut_y,USE.NAMES = F)

# //去除数字
y.out<-gsub("[0-9]+?","",y.out)

# // 去除停止词
s <- read.csv('stopwords.csv')
stopwords <- c(NULL)for (i in 1:length(s))
{
    stopwords[i] <- s[i]
}
y.out <- filter_segment(y.out,stopwords)

# //遍历计数后再组合到一起
wechat_content_whole <- as.array(0)
for (i in 1:length(y.out)){
    table_content <- count(y.out[[i]])
    wechat_content_whole <- rbind(wechat_content_whole,table_content)
}

# //最后计数
wechat_content_whole <- count(wechat_content_whole,"x")

# //从大到小排列
wechat_content_whole<- wechat_content_whole[order(wechat_content_whole$freq,decreasing=TRUE),]

# //提取前1000条做词云
wechat_words_final <- table_content_whole_final[1:1000,]

# //颜色从粉到白函数
clufunc <- colorRampPalette(c("pink","white"))

# //形成词云 
wordcloud2(wechat_words_final, fontFamily = "HYTangTangCuTiJ", figPath = "love.jpg", size=1, color=clufunc(1000))
```


### dbConnect
```{r}
con <- DBI::dbConnect(odbc::odbc(),
                        Driver    = "SQL Server", 
                        Server    = [My Server],
                        Database  = [My Database],
                        UID       = [My User ID],
                        PWD       = [My Password],
                        Port      = 1433)

```


