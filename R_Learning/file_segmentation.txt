在调用worker()函数时，我们实际是在加载jiebaR库的分词引擎。jiebaR库提供了7种分词引擎。

混合模型(MixSegment):是四个分词引擎里面分词效果较好的类，结它合使用最大概率法和隐式马尔科夫模型。
最大概率法(MPSegment) :负责根据Trie树构建有向无环图和进行动态规划算法，是分词算法的核心。
隐式马尔科夫模型(HMMSegment):是根据基于人民日报等语料库构建的HMM模型来进行分词，主要算法思路是根据(B,E,M,S)四个状态来代表每个字的隐藏状态。 HMM模型由dict/hmm_model.utf8提供。分词算法即viterbi算法。
索引模型(QuerySegment):先使用混合模型进行切词，再对于切出来的较长的词，枚举句子中所有可能成词的情况，找出词库里存在。
标记模型(tag)
Simhash模型(simhash)
关键词模型(keywods)
